{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import SpaceTokenizer \n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"888.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['Review']\n",
    "y = data['Liked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initializing = TfidfVectorizer()\n",
    "x_final = Initializing.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_final.toarray()\n",
    "hello = preprocessing.LabelEncoder()\n",
    "y_final = hello.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(a,y_final,test_size = 0.4, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088\n",
      "2984\n",
      "Confusion Matrix\n",
      "[[   0    0    1    0    0]\n",
      " [   0    0    0    1    0]\n",
      " [   0    0 1158  356    0]\n",
      " [   0    0  537  930    0]\n",
      " [   0    0    0    1    0]]\n",
      "Accuracy :  69.97319034852548\n",
      "f1 Score: 69.79787559079386\n",
      "Recall: 69.97319034852548\n",
      "Precision: 70.14009333029408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_network = MLPClassifier( hidden_layer_sizes=(200,250), activation='relu', solver='adam', alpha=0.2, batch_size='auto', learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=5000, shuffle=True, random_state=90, tol=0.001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.8, beta_2=0.8, epsilon=1e-08  )\n",
    "neural_network.fit(x_train, y_train)\n",
    "prediction1 = neural_network.predict(x_test)  \n",
    "count1 = 0\n",
    "for i in range (len(prediction1)):\n",
    "    if(prediction1[i]==y_test[i]):\n",
    "        count1=count1+1\n",
    "\n",
    "print(count1)\n",
    "print(len(prediction1))\n",
    "\n",
    "AccNN=accuracy_score(y_test,prediction1)*100\n",
    "F1NN=f1_score(y_test,prediction1,average='weighted')*100\n",
    "RNN=recall_score(y_test,prediction1,average='weighted')*100\n",
    "PNN=precision_score(y_test,prediction1,average='weighted')*100\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, prediction1))\n",
    "\n",
    "print(\"Accuracy : \",AccNN )\n",
    "\n",
    "print ('f1 Score:',F1NN)\n",
    "\n",
    "print ('Recall:',RNN)\n",
    "\n",
    "print ('Precision:',PNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096\n",
      "2984\n",
      "Confusion Matrix\n",
      "[[   0    0    0    1    0]\n",
      " [   0    0    0    1    0]\n",
      " [   0    0 1025  489    0]\n",
      " [   0    0  396 1071    0]\n",
      " [   0    0    0    1    0]]\n",
      "Accuracy :  70.24128686327077\n",
      "f1 Score: 70.19256139456313\n",
      "Recall: 70.24128686327077\n",
      "Precision: 70.28491454736606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "prediction3 = rf.predict(x_test)\n",
    "\n",
    "\n",
    "count3 = 0\n",
    "for i in range (len(prediction3)):\n",
    "    if(prediction3[i]==y_test[i]):\n",
    "        count3=count3+1\n",
    "\n",
    "print(count3)\n",
    "print(len(prediction3))\n",
    "\n",
    "AccRF=accuracy_score(y_test,prediction3)*100\n",
    "F1RF=f1_score(y_test,prediction3,average='weighted')*100\n",
    "RRF=recall_score(y_test,prediction3,average='weighted')*100\n",
    "PRF=precision_score(y_test,prediction3,average='weighted')*100\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, prediction3))\n",
    "\n",
    "print(\"Accuracy : \",AccRF )\n",
    "\n",
    "print ('f1 Score:',F1RF)\n",
    "\n",
    "print ('Recall:',RRF)\n",
    "\n",
    "print ('Precision:',PRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077\n",
      "2984\n",
      "Confusion Matrix\n",
      "[[   0    0    1    0    0]\n",
      " [   0    0    0    1    0]\n",
      " [   0    0 1056  458    0]\n",
      " [   0    0  446 1021    0]\n",
      " [   0    0    0    1    0]]\n",
      "Accuracy :  69.60455764075067\n",
      "f1 Score: 69.57109488303607\n",
      "Recall: 69.60455764075067\n",
      "Precision: 69.54011247146357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Tulan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "prediction5 = dt.predict(x_test)\n",
    "\n",
    "\n",
    "count5 = 0\n",
    "for i in range (len(prediction5)):\n",
    "    if(prediction5[i]==y_test[i]):\n",
    "        count5=count5+1\n",
    "\n",
    "print(count5)\n",
    "print(len(prediction5))\n",
    "AccDT=accuracy_score(y_test,prediction5)*100\n",
    "F1DT=f1_score(y_test,prediction5,average='weighted')*100\n",
    "RDT=recall_score(y_test,prediction5,average='weighted')*100\n",
    "PDT=precision_score(y_test,prediction5,average='weighted')*100\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, prediction5))\n",
    "\n",
    "print(\"Accuracy : \",AccDT )\n",
    "\n",
    "print ('f1 Score:',F1DT)\n",
    "\n",
    "print ('Recall:',RDT)\n",
    "\n",
    "print ('Precision:',PDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
